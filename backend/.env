# LLM Provider Configuration
LLM_PROVIDER=ollama

# Ollama Settings (only used if LLM_PROVIDER=ollama)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=phi3.5

# LLM Parameters
# Lower temperature = more deterministic/consistent responses
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=2048

# Database Configuration
# PostgreSQL - sanjeevani_finaldb
DATABASE_URL=postgresql://postgres:siddharth%402004@localhost:5432/sanjeevani_finaldb

# For MySQL (production):
# DATABASE_URL=mysql+pymysql://user:password@localhost:3306/sanjeevani

# JWT Secret Key - CHANGE THIS IN PRODUCTION
SECRET_KEY=your-super-secret-key-change-in-production-at-least-32-chars-long

# Note: Phi-3.5 is the FASTEST Ollama model (~2 seconds per response on most systems)
# Phi-3.5 is a 3.8 billion parameter model optimized for speed
# Available models: phi3.5 (fastest), mistral (balanced), neural-chat (slower but detailed)
