# LLM Provider Configuration
LLM_PROVIDER=ollama

# Ollama Settings (only used if LLM_PROVIDER=ollama)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=meditron

# LLM Parameters
# Lower temperature = more deterministic/consistent responses
# Reduced tokens for faster Meditron-7B responses (medical model is compute-intensive)
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=1024

# Database Configuration
# Azure PostgreSQL - sanjeevani_finaldb
# Azure PostgreSQL requires SSL connection
DATABASE_URL=postgresql://sma_admin:Sanjeevani%4026@sma-sanjeevani.postgres.database.azure.com:5432/sanjeevani_finaldb?sslmode=require

# For MySQL (production):
# DATABASE_URL=mysql+pymysql://user:password@localhost:3306/sanjeevani

# JWT Secret Key - CHANGE THIS IN PRODUCTION
SECRET_KEY=your-super-secret-key-change-in-production-at-least-32-chars-long

# Note: Phi-3.5 is the FASTEST Ollama model (~2 seconds per response on most systems)
# Phi-3.5 is a 3.8 billion parameter model optimized for speed
# Available models: phi3.5 (fastest), mistral (balanced), neural-chat (slower but detailed)

# TTS Configuration (Enhanced TTS Service)
USE_BHASHINI_TTS=true          # Use Bhashini TTS (free, recommended for Indian languages)
USE_GOOGLE_TTS=false           # Use Google Cloud TTS (requires API key, best quality)
USE_GTTS=true                  # Use gTTS as fallback (free, reliable)

# Google Cloud TTS (Optional - only if USE_GOOGLE_TTS=true)
# GOOGLE_TTS_API_KEY=your-google-cloud-api-key-here

# Bhashini API Key (Optional - works without key for basic usage, 250 char limit)
# Get free API key from: https://bhashini.ai/
# BHASHINI_API_KEY=your-bhashini-api-key-here