# LLM Provider Configuration
# Options: "mock" (for testing), "ollama" (for local Mistral-7B)
LLM_PROVIDER=mock

# Ollama Settings (only used if LLM_PROVIDER=ollama)
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# LLM Parameters
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=1024
