import os
import json
import logging
from typing import Dict, Callable, Optional, List

import requests

from . import prompt_templates, safety_rules, utils
from .models import SymptomRequest, SymptomResponse, MedicineRecommendation
from .translation_service import (
    translate_symptoms_to_english,
    translate_response_to_language,
    translate_json_response,
    translation_service
)

logger = logging.getLogger(__name__)


# Symptom to medicine mapping for intelligent fallback
SYMPTOM_MEDICINE_MAP = {
    "fever": {
        "condition": "Fever",
        "medicines": [
            {"name": "Paracetamol 500mg", "dosage": "1 tablet", "frequency": "twice daily", "duration": "3 days"},
            {"name": "Ibuprofen 400mg", "dosage": "1 tablet", "frequency": "twice daily", "duration": "3 days"}
        ]
    },
    "cough": {
        "condition": "Cough",
        "medicines": [
            {"name": "Cough Syrup (Dextromethorphan)", "dosage": "10ml", "frequency": "3-4 times daily", "duration": "5 days"},
            {"name": "Throat Lozenges", "dosage": "1 lozenge", "frequency": "every 2 hours", "duration": "5 days"}
        ]
    },
    "cold": {
        "condition": "Common Cold",
        "medicines": [
            {"name": "Decongestant nasal spray", "dosage": "2 sprays per nostril", "frequency": "3 times daily", "duration": "3-5 days"},
            {"name": "Vitamin C tablets 500mg", "dosage": "1 tablet", "frequency": "twice daily", "duration": "7 days"}
        ]
    },
    "headache": {
        "condition": "Headache",
        "medicines": [
            {"name": "Paracetamol 500mg", "dosage": "1 tablet", "frequency": "twice daily", "duration": "3 days"},
            {"name": "Aspirin 325mg", "dosage": "1 tablet", "frequency": "twice daily", "duration": "3 days"}
        ]
    },
    "body pain": {
        "condition": "Body Pain",
        "medicines": [
            {"name": "Ibuprofen 400mg", "dosage": "1 tablet", "frequency": "twice daily", "duration": "3 days"},
            {"name": "Muscle relaxant (Paracetamol + Chlorzoxazone)", "dosage": "1 tablet", "frequency": "twice daily", "duration": "5 days"}
        ]
    },
    "throat pain": {
        "condition": "Throat Pain/Sore Throat",
        "medicines": [
            {"name": "Throat lozenges with benzocaine", "dosage": "1 lozenge", "frequency": "every 2 hours", "duration": "5 days"},
            {"name": "Antiseptic throat spray", "dosage": "2-3 sprays", "frequency": "4 times daily", "duration": "5 days"}
        ]
    },
    "diarrhea": {
        "condition": "Diarrhea",
        "medicines": [
            {"name": "Oral Rehydration Salts (ORS)", "dosage": "1 sachet", "frequency": "after each loose stool", "duration": "till diarrhea stops"},
            {"name": "Loperamide 2mg", "dosage": "1 tablet", "frequency": "twice daily", "duration": "2 days"}
        ]
    },
    "constipation": {
        "condition": "Constipation",
        "medicines": [
            {"name": "Isabgol (Psyllium husk)", "dosage": "1 teaspoon", "frequency": "once daily at bedtime", "duration": "3-5 days"},
            {"name": "Liquid paraffin", "dosage": "1-2 tablespoons", "frequency": "once daily", "duration": "3-5 days"}
        ]
    },
    "acidity": {
        "condition": "Acidity/Heartburn",
        "medicines": [
            {"name": "Antacid (Magnesium Hydroxide)", "dosage": "1-2 tablespoons", "frequency": "3 times daily after meals", "duration": "5-7 days"},
            {"name": "Omeprazole 20mg", "dosage": "1 capsule", "frequency": "once daily", "duration": "7-14 days"}
        ]
    },
    "allergy": {
        "condition": "Allergy",
        "medicines": [
            {"name": "Antihistamine (Cetirizine 10mg)", "dosage": "1 tablet", "frequency": "once daily", "duration": "5-7 days"},
            {"name": "Antihistamine (Loratadine 10mg)", "dosage": "1 tablet", "frequency": "once daily", "duration": "5-7 days"}
        ]
    },
    "nausea": {
        "condition": "Nausea/Vomiting",
        "medicines": [
            {"name": "Domperidone 10mg", "dosage": "1 tablet", "frequency": "3 times daily before meals", "duration": "3-5 days"},
            {"name": "Ondansetron 4mg", "dosage": "1 tablet", "frequency": "twice daily", "duration": "3 days"}
        ]
    }
}


def _generate_symptom_aware_fallback(symptoms: List[str], age: int = 30) -> Dict:
    """Generate a symptom-appropriate fallback response when LLM fails."""
    symptoms_str = " ".join(symptoms).lower() if symptoms else ""
    
    # Find matching symptoms
    matched_condition = None
    matched_medicines = None
    
    for symptom_key, medicine_info in SYMPTOM_MEDICINE_MAP.items():
        if symptom_key in symptoms_str:
            matched_condition = medicine_info["condition"]
            matched_medicines = medicine_info["medicines"]
            break
    
    # If no specific match, find closest match
    if not matched_medicines:
        for symptom_key, medicine_info in SYMPTOM_MEDICINE_MAP.items():
            for symptom in symptoms:
                if symptom_key.split()[0] in symptom.lower():
                    matched_condition = medicine_info["condition"]
                    matched_medicines = medicine_info["medicines"]
                    break
            if matched_medicines:
                break
    
    # Default if still no match
    if not matched_medicines:
        matched_condition = "General Illness"
        matched_medicines = [
            {"name": "Paracetamol 500mg", "dosage": "1 tablet", "frequency": "twice daily", "duration": "3 days"}
        ]
    
    # Format medicines with proper structure
    formatted_medicines = []
    for med in matched_medicines:
        formatted_medicines.append({
            "name": med["name"],
            "dosage": med["dosage"],
            "frequency": med["frequency"],
            "duration": med["duration"],
            "instructions": f"Take {med['dosage']} {med['frequency']}, {med['duration']}",
            "warnings": ["Consult doctor if symptoms persist", "Check allergies before use"]
        })
    
    return {
        "predicted_condition": matched_condition,
        "symptom_analysis": f"Based on reported symptoms: {', '.join(symptoms)}",
        "recommended_medicines": formatted_medicines,
        "home_care_advice": [
            "Rest adequately",
            "Drink plenty of water and fluids",
            "Avoid strenuous activities",
            "Eat light, nutritious food"
        ],
        "doctor_consultation_advice": "Consult a doctor if symptoms persist for more than 3-5 days or worsen",
        "disclaimer": "This is not a professional diagnosis. Please consult a qualified doctor for proper evaluation."
    }


# Optional translator: try to import IndicTrans2-style package if available
_translator: Optional[Callable[[str, str], str]] = None
try:
    # Attempt common names; if not present, translator remains None
    from indic_trans2 import translate as _indic_translate  # type: ignore

    def _translate(text: str, lang: str) -> str:
        return _indic_translate(text, target_lang=lang)

    _translator = _translate
except Exception:
    try:
        from indictrans import translate as _indic_translate2  # type: ignore

        def _translate2(text: str, lang: str) -> str:
            return _indic_translate2(text, lang)

        _translator = _translate2
    except Exception:
        _translator = None


def call_llm(prompt: str) -> str:
    provider = os.environ.get("LLM_PROVIDER", "ollama").lower().strip()
    logger.info("=" * 70)
    logger.info("üîß Symptoms Recommendation Service using LLM PROVIDER: '%s'", provider)
    if provider == "azure_openai":
        logger.info("‚úÖ USING AZURE OPENAI (NOT LOCAL OLLAMA)")
    logger.info("=" * 70)
    
    if provider == "mock":
        logger.warning("!!! WARNING: Using MOCK provider - NOT calling real LLM !!!")
        logger.warning("To use real Phi-4, set LLM_PROVIDER=ollama or azure_openai in .env")
        raise ValueError("Mock provider disabled. Set LLM_PROVIDER=ollama or azure_openai in .env to use Phi-4")
    
    if provider == "azure_openai":
        logger.info("Calling Phi-4 via Azure OpenAI for independent medical reasoning...")
        
        # Get Azure OpenAI configuration from environment
        azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT", "").strip()
        azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY", "").strip()
        azure_deployment = os.environ.get("AZURE_OPENAI_DEPLOYMENT_NAME", "Sanjeevani-Phi-4").strip()
        
        if not azure_endpoint or not azure_api_key:
            raise ValueError("Azure OpenAI credentials missing. Set AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY in .env")
        
        # Azure OpenAI uses OpenAI-compatible API
        # Remove '/openai/v1/' from endpoint if present and reconstruct proper URL
        base_endpoint = azure_endpoint.replace("/openai/v1/", "").rstrip("/")
        api_url = f"{base_endpoint}/openai/deployments/{azure_deployment}/chat/completions?api-version=2024-02-15-preview"
        
        logger.info("Azure Endpoint: %s", base_endpoint)
        logger.info("Deployment: %s", azure_deployment)
        
        payload = {
            "messages": [
                {"role": "system", "content": "You are a medical AI assistant. Respond only with valid JSON."},
                {"role": "user", "content": prompt}
            ],
            "temperature": float(os.environ.get("LLM_TEMPERATURE", 0.2)),
            "max_tokens": int(os.environ.get("LLM_MAX_TOKENS", 1024)),
        }
        
        headers = {
            "Content-Type": "application/json",
            "api-key": azure_api_key
        }
        
        try:
            logger.info("Sending request to Azure OpenAI...")
            resp = requests.post(api_url, json=payload, headers=headers, timeout=600)
            
            if resp.status_code != 200:
                error_msg = resp.text
                logger.error("Azure OpenAI error (status %d): %s", resp.status_code, error_msg)
                raise Exception(f"Azure OpenAI error: {resp.status_code} - {error_msg}")
            
            resp.raise_for_status()
            
            # Azure OpenAI returns OpenAI-compatible format
            resp_json = resp.json()
            llm_output = resp_json.get("choices", [{}])[0].get("message", {}).get("content", "")
            
            logger.info("‚úì Azure OpenAI (Phi-4) response received")
            
            # Try to extract JSON from the response
            try:
                parsed = utils.try_parse_json(llm_output)
                logger.info("‚úì Successfully parsed Azure OpenAI response")
                return json.dumps(parsed)
            except Exception as parse_err:
                logger.error("‚úó Failed to parse JSON from Azure OpenAI response")
                logger.error("Parse error: %s", parse_err)
                raise ValueError(f"Azure OpenAI did not return valid JSON. Error: {parse_err}")
                
        except requests.exceptions.ConnectionError as ce:
            logger.error("‚úó FATAL: Cannot connect to Azure OpenAI")
            logger.error("Azure Endpoint: %s", azure_endpoint)
            logger.error("Error: %s", ce)
            raise Exception(
                f"Cannot connect to Azure OpenAI at {azure_endpoint}\n\n"
                f"Solutions:\n"
                f"1. Verify AZURE_OPENAI_ENDPOINT is correct in .env\n"
                f"2. Check AZURE_OPENAI_API_KEY is valid\n"
                f"3. Ensure network connectivity to Azure"
            )
        except Exception as e:
            logger.exception("‚úó ERROR calling Azure OpenAI: %s", e)
            raise
    
    elif provider == "ollama":
        logger.info("Calling Phi-4 via Ollama for independent medical reasoning...")
        ollama_url = os.environ.get("OLLAMA_URL", "http://localhost:11434").strip()
        ollama_model = os.environ.get("OLLAMA_MODEL", "phi4").strip()
        
        logger.info("Model: %s", ollama_model)
        
        api_url = f"{ollama_url}/api/generate"
        payload = {
            "model": ollama_model,
            "prompt": prompt,
            "stream": False,
            "temperature": float(os.environ.get("LLM_TEMPERATURE", 0.3)),
            "num_predict": 512,  # Limit to 512 tokens for faster generation
        }
        
        try:
            logger.info("Sending request to Phi-4...")
            resp = requests.post(api_url, json=payload, timeout=600)
            
            if resp.status_code != 200:
                error_msg = resp.text
                logger.error("Ollama error (status %d): %s", resp.status_code, error_msg)
                raise Exception(f"Ollama error: {resp.status_code} - {error_msg}")
            
            resp.raise_for_status()
            
            # Ollama returns {"response": "...text..."} format
            resp_json = resp.json()
            llm_output = resp_json.get("response", "")
            
            logger.info("‚úì Phi-4 response received")
            
            # Try to extract JSON from the response
            try:
                parsed = utils.try_parse_json(llm_output)
                logger.info("‚úì Successfully parsed Phi-4 response")
                return json.dumps(parsed)
            except Exception as parse_err:
                logger.error("‚úó Failed to parse JSON from Phi-4 response")
                logger.error("Parse error: %s", parse_err)
                raise ValueError(f"Phi-4 did not return valid JSON. Error: {parse_err}")
                
        except requests.exceptions.ConnectionError as ce:
            logger.error("‚úó FATAL: Cannot connect to Ollama (Phi-4)")
            logger.error("Ollama URL: %s", ollama_url)
            logger.error("Error: %s", ce)
            raise Exception(
                f"Cannot connect to Ollama at {ollama_url}\n\n"
                f"Solutions:\n"
                f"1. Make sure Ollama is running: ollama serve\n"
                f"2. Verify Phi-4 model is installed: ollama list\n"
                f"3. Check OLLAMA_URL in .env is correct"
            )
        except Exception as e:
            logger.exception("‚úó ERROR calling Ollama/Phi-4: %s", e)
            raise
    
    else:
        logger.error("Invalid LLM_PROVIDER: %s", provider)
        raise ValueError(f"Invalid LLM_PROVIDER: {provider}. Must be 'ollama' or 'azure_openai'. Set in .env file.")


def _translate_text_if_needed(text: str, lang: str) -> str:
    """
    Translate text to the target language if translator is available.
    If translator is not available, returns original text with a warning.
    """
    if not text:
        return text
    if not lang or lang.lower().startswith("en"):
        return text
    if _translator is None:
        logger.warning("‚ö†Ô∏è Translator not available; LLM should generate in %s but translator fallback unavailable", lang)
        logger.warning("‚ö†Ô∏è Consider installing indic-trans2: pip install indic-trans2")
        # Return original text - LLM should have generated in correct language anyway
        return text
    try:
        translated = _translator(text, lang)
        logger.debug("Translated text: '%s' -> '%s' (first 50 chars)", text[:50], translated[:50])
        return translated
    except Exception as e:
        logger.exception("Translation failed for text: %s", str(e))
        # Return original text if translation fails
        return text


def translate_if_needed(resp: Dict, lang: str) -> Dict:
    if not lang or lang.lower().startswith("en"):
        return resp

    # Translate top-level scalar fields
    if "predicted_condition" in resp:
        resp["predicted_condition"] = _translate_text_if_needed(resp.get("predicted_condition", ""), lang)

    if "doctor_consultation_advice" in resp:
        resp["doctor_consultation_advice"] = _translate_text_if_needed(resp.get("doctor_consultation_advice", ""), lang)

    if "disclaimer" in resp:
        resp["disclaimer"] = _translate_text_if_needed(resp.get("disclaimer", ""), lang)

    # Translate lists
    if "home_care_advice" in resp and isinstance(resp.get("home_care_advice"), list):
        resp["home_care_advice"] = [
            _translate_text_if_needed(x, lang) for x in resp.get("home_care_advice", [])
        ]

    # Translate medicines
    meds = resp.get("recommended_medicines", [])
    translated_meds = []
    for m in meds:
        nm = dict(m)
        if "instructions" in nm:
            nm["instructions"] = _translate_text_if_needed(nm.get("instructions", ""), lang)
        if "warnings" in nm and isinstance(nm.get("warnings"), list):
            nm["warnings"] = [
                _translate_text_if_needed(w, lang) for w in nm.get("warnings", [])
            ]
        translated_meds.append(nm)
    resp["recommended_medicines"] = translated_meds

    return resp


def recommend_symptoms(req: SymptomRequest) -> SymptomResponse:
    logger.info("=== NEW RECOMMENDATION REQUEST ===")
    body = req.dict()
    logger.info("Request body: %s", body)
    logger.info("Language requested: %s", req.language)
    
    # Get user's language
    user_language = req.language.lower().strip() if req.language else "english"
    
    # Step 1: Translate symptoms to English if needed (for processing)
    original_symptoms = body.get("symptoms", [])
    if user_language != "english":
        logger.info(f"Translating symptoms from {user_language} to English for LLM processing")
        english_symptoms = translate_symptoms_to_english(original_symptoms, user_language)
        body["symptoms"] = english_symptoms
        logger.info(f"Translated symptoms: {english_symptoms}")
    
    # Step 2: Build prompt - Phi-4 will think independently
    prompt = prompt_templates.build_prompt(body, rag_context="")
    logger.info("Prompt built - Phi-4 will generate recommendations independently")
    
    # Step 3: Call LLM for independent thinking
    try:
        raw = call_llm(prompt)
        parsed = utils.try_parse_json(raw)
    except Exception as llm_err:
        # Fallback: Generate a symptom-aware response using RAG
        logger.warning("LLM failed: %s. Using intelligent fallback response...", str(llm_err))
        symptoms = body.get("symptoms", [])
        
        # Generate symptom-appropriate fallback using RAG medicines
        fallback_response = _generate_symptom_aware_fallback(symptoms, body.get("age", 30))
        parsed = fallback_response

    # Step 5: Translate response back to user's language if needed
    if user_language != "english":
        logger.info(f"Translating response back to {user_language}")
        parsed = translate_json_response(parsed, user_language)
        logger.info(f"‚úÖ Response translated to {user_language}")

    # Language verification and fallback translation if needed
    language = req.language.lower().strip() if req.language else "english"
    if language != "english" and language not in ["en"]:
        # Check if the response seems to be in English (simple heuristic)
        # If so, translate it
        first_text = (
            parsed.get("predicted_condition", "") + 
            " ".join(parsed.get("home_care_advice", [])[:1]) +
            parsed.get("doctor_consultation_advice", "")
        )
        # Check if it contains non-ASCII characters (likely in target language)
        if first_text and len(first_text) > 10:
            has_non_ascii = any(ord(c) > 127 for c in first_text[:200])
            if not has_non_ascii:
                logger.info("‚ö†Ô∏è Response appears to be in English, translating to %s...", language)
                parsed = translate_if_needed(parsed, language)
                logger.info("‚úÖ Translation completed for %s", language)
            else:
                logger.info("‚úÖ Response appears to already be in %s language", language)
        else:
            # If text is too short, translate anyway to be safe
            logger.info("‚ö†Ô∏è Text too short to verify, translating to %s to ensure correctness...", language)
            parsed = translate_if_needed(parsed, language)
    else:
        logger.info("English language requested, no translation needed")

    # Apply safety filters
    parsed = safety_rules.sanitize_response(parsed, req.allergies, req.pregnancy_status, req.existing_conditions)

    # Create TTS payload
    tts = utils.generate_tts_payload(parsed)
    parsed["tts_payload"] = tts

    # Ensure disclaimer exists in the correct language
    if "disclaimer" not in parsed or not parsed.get("disclaimer"):
        # Generate disclaimer in the requested language
        language = req.language.lower().strip() if req.language else "english"
        if language != "english" and language not in ["en"]:
            # Use translation function to get disclaimer in the correct language
            parsed["disclaimer"] = _translate_text_if_needed(
                "This is not a medical diagnosis. Consult a doctor for serious symptoms.",
                language
            )
        else:
            parsed["disclaimer"] = "This is not a medical diagnosis. Consult a doctor for serious symptoms."

    # Build Pydantic response
    meds = []
    for m in parsed.get("recommended_medicines", []):
        meds.append(MedicineRecommendation(**m))

    resp = SymptomResponse(
        predicted_condition=parsed.get("predicted_condition", "Unknown"),
        recommended_medicines=meds,
        home_care_advice=parsed.get("home_care_advice", []),
        doctor_consultation_advice=parsed.get("doctor_consultation_advice", ""),
        disclaimer=parsed.get("disclaimer", ""),
        tts_payload=parsed.get("tts_payload"),
    )

    return resp


def answer_medical_question(question: str, language: str = "english") -> str:
    """
    Answer ANY question using Phi-4 LLM as a medical assistant.
    The LLM intelligently determines if it's medical and responds appropriately.
    Works with medical terms from around the world in multiple languages.
    Acts like ChatGPT for medical knowledge.
    """
    logger.info("=" * 70)
    logger.info("MEDICAL Q&A: %s", question)
    logger.info("Language: %s", language)
    logger.info("=" * 70)

    # Language mapping for prompt
    lang_names = {
        "english": "English",
        "telugu": "Telugu (‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å)",
        "hindi": "Hindi (‡§π‡§ø‡§®‡•ç‡§¶‡•Ä)",
        "marathi": "Marathi (‡§Æ‡§∞‡§æ‡§†‡•Ä)",
        "bengali": "Bengali (‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ)",
        "tamil": "Tamil (‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç)",
        "kannada": "Kannada (‡≤ï‡≤®‡≥ç‡≤®‡≤°)",
        "malayalam": "Malayalam (‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç)",
        "gujarati": "Gujarati (‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä)",
    }
    lang_display = lang_names.get(language.lower(), "English")

    # Create a comprehensive prompt for medical Q&A
    # The LLM itself will determine if the question is medical
    # Using Phi-4 (Microsoft), a powerful general-purpose language model optimized for medical expertise
    prompt = f"""You are Sanjeevani, an advanced AI medical assistant trained on global medical knowledge.
Your role is to:
1. Answer medical, health, and healthcare-related questions comprehensively
2. Support multiple languages and medical terminology from around the world
3. Provide accurate, evidence-based medical information
4. Always emphasize consulting healthcare professionals for serious concerns
5. Handle rare diseases, specific conditions, and complex medical scenarios
6. Explain medical concepts clearly for lay people

LANGUAGE INSTRUCTION (CRITICAL - MUST FOLLOW):
- The user's preferred language is: {lang_display}
- YOU MUST ALWAYS RESPOND IN {lang_display.upper()} LANGUAGE, regardless of the question language
- Even if the question is in English, you MUST respond in {lang_display}
- If the question is in a different language, still respond in {lang_display}
- This is a requirement for rural users who need responses in their native language
- DO NOT match the question language - ALWAYS use {lang_display}

IMPORTANT RULES:
- If the question is about health, medicine, disease, symptoms, treatment, prevention, or healthcare: ANSWER COMPREHENSIVELY
- If the question is NOT medical: Politely decline and redirect to medical topics (in {lang_display})
- Always include safety disclaimers when appropriate (in {lang_display})
- Never diagnose definitively - provide information and suggest professional consultation (in {lang_display})
- Accept medical terms in any language and from any medical tradition
- Be thorough but concise (2-5 sentences for simple questions, more for complex ones)
- Respond ONLY with the answer text, no JSON formatting, no markdown
- CRITICAL: RESPOND ENTIRELY IN {lang_display.upper()} LANGUAGE - NO EXCEPTIONS

Question from user: {question}

Response (in {lang_display}):"""

    try:
        logger.info("Calling LLM for medical Q&A...")
        
        # Get LLM config
        provider = os.environ.get("LLM_PROVIDER", "ollama").lower().strip()
        
        logger.info("üîß Medical Q&A using LLM Provider: %s", provider)
        if provider == "azure_openai":
            logger.info("‚úÖ CONFIRMED: Using Azure OpenAI Phi-4 (NOT local Ollama)")
        
        if provider == "azure_openai":
            # Azure OpenAI implementation
            azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT", "").strip()
            azure_api_key = os.environ.get("AZURE_OPENAI_API_KEY", "").strip()
            azure_deployment = os.environ.get("AZURE_OPENAI_DEPLOYMENT_NAME", "Sanjeevani-Phi-4").strip()
            
            if not azure_endpoint or not azure_api_key:
                raise ValueError("Azure OpenAI credentials missing. Set AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY in .env")
            
            base_endpoint = azure_endpoint.replace("/openai/v1/", "").rstrip("/")
            api_url = f"{base_endpoint}/openai/deployments/{azure_deployment}/chat/completions?api-version=2024-02-15-preview"
            
            payload = {
                "messages": [
                    {"role": "system", "content": f"You are a medical AI assistant. Respond ENTIRELY in {lang_display} language."},
                    {"role": "user", "content": prompt}
                ],
                "temperature": float(os.environ.get("LLM_TEMPERATURE", 0.3)),
                "max_tokens": int(os.environ.get("LLM_MAX_TOKENS", 1024)),
            }
            
            headers = {
                "Content-Type": "application/json",
                "api-key": azure_api_key
            }
            
            logger.info("Sending request to Azure OpenAI (Phi-4)...")
            logger.info("Timeout: 60 seconds for medical Q&A response")
            
            resp = requests.post(api_url, json=payload, headers=headers, timeout=60)
            
            if resp.status_code != 200:
                error_msg = resp.text
                logger.error("Azure OpenAI error (status %d): %s", resp.status_code, error_msg)
                raise Exception(f"Azure OpenAI API error: {resp.status_code} - {error_msg}")
            
            resp.raise_for_status()
            
            # Extract response from Azure OpenAI
            resp_json = resp.json()
            answer = resp_json.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
            
        elif provider == "ollama":
            ollama_url = os.environ.get("OLLAMA_URL", "http://localhost:11434").strip()
            ollama_model = os.environ.get("OLLAMA_MODEL", "phi4").strip()
            
            logger.info("Ollama URL: %s", ollama_url)
            logger.info("Ollama Model: %s (Phi-4)", ollama_model)
            
            # Call Ollama directly without JSON parsing
            api_url = f"{ollama_url}/api/generate"
            payload = {
                "model": ollama_model,
                "prompt": prompt,
                "stream": False,
                "temperature": float(os.environ.get("LLM_TEMPERATURE", 0.3)),
            }
            
            logger.info("Sending request to Phi-4 via Ollama...")
            logger.info("Timeout: 60 seconds for Phi-4 medical Q&A response")
            
            resp = requests.post(api_url, json=payload, timeout=60)
            
            if resp.status_code != 200:
                error_msg = resp.text
                logger.error("Ollama error (status %d): %s", resp.status_code, error_msg)
                raise Exception(f"Ollama API error: {resp.status_code} - {error_msg}")
            
            resp.raise_for_status()
            
            # Extract response from Ollama
            resp_json = resp.json()
            answer = resp_json.get("response", "").strip()
        
        else:
            raise Exception(f"Invalid LLM_PROVIDER: {provider}. Must be 'ollama' or 'azure_openai'")
        
        logger.info("‚úì LLM response received (%d chars)", len(answer))
        logger.info("Response (first 500 chars): %s", answer[:500])
        
        # Validate response
        if not answer or len(answer) < 5:
            logger.warning("Response too short or empty, using fallback")
            # Fallback message in the requested language
            fallback_messages = {
                "english": "I couldn't generate a proper response. Please try rephrasing your medical question.",
                "hindi": "‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§â‡§ö‡§ø‡§§ ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∏‡§ï‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•á ‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡•ã ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§≤‡§ø‡§ñ‡§®‡•á ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§",
                "telugu": "‡∞®‡±á‡∞®‡±Å ‡∞∏‡∞∞‡±à‡∞® ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞∏‡±ç‡∞™‡∞Ç‡∞¶‡∞®‡∞®‡±Å ‡∞â‡∞§‡±ç‡∞™‡∞§‡±ç‡∞§‡∞ø ‡∞ö‡±á‡∞Ø‡∞≤‡±á‡∞ï‡∞™‡±ã‡∞Ø‡∞æ‡∞®‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡±Ä ‡∞µ‡±à‡∞¶‡±ç‡∞Ø ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø‡•§",
                "marathi": "‡§Æ‡•Ä ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡§æ‡§¶ ‡§µ‡•ç‡§Ø‡•Å‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§∞‡•Ç ‡§∂‡§ï‡§≤‡•ã ‡§®‡§æ‡§π‡•Ä. ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ü‡§™‡§≤‡§æ ‡§µ‡•à‡§¶‡•ç‡§Ø‡§ï‡•Ä‡§Ø ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§≤‡§ø‡§π‡§ø‡§£‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡§∞‡§æ.",
                "bengali": "‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡¶†‡¶ø‡¶ï ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø‡¶®‡¶ø‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ö‡¶ø‡¶ï‡¶ø‡ßé‡¶∏‡¶æ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡¶ü‡¶ø ‡¶™‡ßÅ‡¶®‡¶∞‡¶æ‡¶Ø‡¶º ‡¶≤‡¶ø‡¶ñ‡¶§‡ßá ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§",
                "tamil": "‡Æ®‡Ææ‡Æ©‡Øç ‡Æö‡Æ∞‡Æø‡ÆØ‡Ææ‡Æ© ‡Æ™‡Æ§‡Æø‡Æ≤‡Øà ‡Æâ‡Æ∞‡ØÅ‡Æµ‡Ææ‡Æï‡Øç‡Æï ‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡Æµ‡Æø‡Æ≤‡Øç‡Æ≤‡Øà. ‡Æ§‡ÆØ‡Æµ‡ØÅ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æ∞‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø‡ÆØ‡Øà ‡ÆÆ‡ØÄ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡Æé‡Æ¥‡ØÅ‡Æ§ ‡ÆÆ‡ØÅ‡ÆØ‡Æ±‡Øç‡Æö‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç‡•§",
                "kannada": "‡≤®‡≤æ‡≤®‡≥Å ‡≤∏‡≤∞‡≤ø‡≤Ø‡≤æ‡≤¶ ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤ø‡≤∏‡≤≤‡≥Å ‡≤∏‡≤æ‡≤ß‡≥ç‡≤Ø‡≤µ‡≤æ‡≤ó‡≤≤‡≤ø‡≤≤‡≥ç‡≤≤. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø‡≤ï‡≥Ä‡≤Ø ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü ‡≤¨‡≤∞‡≥Ü‡≤Ø‡≤≤‡≥Å ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≤ø.",
                "malayalam": "‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥∂‡¥∞‡¥ø‡¥Ø‡¥æ‡¥Ø ‡¥™‡µç‡¥∞‡¥§‡¥ø‡¥ï‡¥∞‡¥£‡¥Ç ‡¥∏‡µÉ‡¥∑‡µç‡¥ü‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥ï‡¥¥‡¥ø‡¥û‡µç‡¥û‡¥ø‡¥≤‡µç‡¥≤. ‡¥¶‡¥Ø‡¥µ‡¥æ‡¥Ø‡¥ø ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥Æ‡µÜ‡¥°‡¥ø‡¥ï‡µç‡¥ï‡µΩ ‡¥ö‡µã‡¥¶‡µç‡¥Ø‡¥Ç ‡¥µ‡µÄ‡¥£‡µç‡¥ü‡µÅ‡¥Ç ‡¥é‡¥¥‡µÅ‡¥§‡¥æ‡µª ‡¥∂‡µç‡¥∞‡¥Æ‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï.",
                "gujarati": "‡™π‡´Å‡™Ç ‡™Ø‡´ã‡™ó‡´ç‡™Ø ‡™™‡´ç‡™∞‡™§‡™ø‡™≠‡™æ‡™µ ‡™â‡™§‡´ç‡™™‡™®‡´ç‡™® ‡™ï‡™∞‡´Ä ‡™∂‡™ï‡´ç‡™Ø‡´ã ‡™®‡™•‡´Ä. ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™§‡™Æ‡™æ‡™∞‡™æ ‡™§‡™¨‡´Ä‡™¨‡´Ä ‡™™‡´ç‡™∞‡™∂‡´ç‡™®‡™®‡´á ‡™´‡™∞‡´Ä‡™•‡´Ä ‡™≤‡™ñ‡™µ‡™æ‡™®‡´ã ‡™™‡´ç‡™∞‡™Ø‡™æ‡™∏ ‡™ï‡™∞‡´ã.",
            }
            answer = fallback_messages.get(language.lower(), fallback_messages["english"])
        
        # Final check: If answer is in English but non-English was requested, log a warning
        if language.lower() != "english" and language.lower() not in ["en"]:
            non_ascii_count = sum(1 for c in answer[:200] if ord(c) > 127)
            if non_ascii_count < 5:
                logger.warning("‚ö†Ô∏è LLM response appears to be in English despite %s language request", language)
            else:
                logger.info("‚úÖ LLM response appears to be in %s language", language)
        
        return answer
        
    except requests.exceptions.ConnectionError as ce:
        logger.error("Connection error to Ollama: %s", ce)
        error_messages = {
            "english": f"Cannot connect to LLM service at {os.environ.get('OLLAMA_URL', 'http://localhost:11434')}. Please ensure Ollama is running with: ollama serve",
            "hindi": f"LLM ‡§∏‡•á‡§µ‡§æ ‡§∏‡•á ‡§ï‡§®‡•á‡§ï‡•ç‡§ü ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§∏‡§ï‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø Ollama ‡§ö‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à: ollama serve",
            "telugu": f"LLM ‡∞∏‡±á‡∞µ‡∞ï‡±Å ‡∞ï‡∞®‡±Ü‡∞ï‡±ç‡∞ü‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç ‡∞∏‡∞æ‡∞ß‡±ç‡∞Ø‡∞™‡∞°‡∞≤‡±á‡∞¶‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø Ollama ‡∞®‡∞°‡±Å‡∞∏‡±ç‡∞§‡±ã‡∞Ç‡∞¶‡∞®‡∞ø ‡∞®‡∞ø‡∞∞‡±ç‡∞ß‡∞æ‡∞∞‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø: ollama serve",
            "marathi": f"LLM ‡§∏‡•á‡§µ‡•á‡§∂‡•Ä ‡§ï‡§®‡•á‡§ï‡•ç‡§ü ‡§π‡•ã‡§ä ‡§∂‡§ï‡§≤‡•á ‡§®‡§æ‡§π‡•Ä. ‡§ï‡•É‡§™‡§Ø‡§æ Ollama ‡§ö‡§æ‡§≤‡•Ç ‡§Ü‡§π‡•á ‡§Ø‡§æ‡§ö‡•Ä ‡§ñ‡§æ‡§§‡•ç‡§∞‡•Ä ‡§ï‡§∞‡§æ: ollama serve",
            "bengali": f"LLM ‡¶™‡¶∞‡¶ø‡¶∑‡ßá‡¶¨‡¶æ‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶∏‡¶Ç‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º‡¶®‡¶ø‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶Ø‡ßá Ollama ‡¶ö‡¶≤‡¶õ‡ßá: ollama serve",
            "tamil": f"LLM ‡Æö‡Øá‡Æµ‡Øà‡ÆØ‡ØÅ‡Æü‡Æ©‡Øç ‡Æá‡Æ£‡Øà‡Æï‡Øç‡Æï ‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡Æµ‡Æø‡Æ≤‡Øç‡Æ≤‡Øà. ‡Æ§‡ÆØ‡Æµ‡ØÅ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ Ollama ‡Æá‡ÆØ‡Æô‡Øç‡Æï‡ØÅ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ ‡Æé‡Æ©‡Øç‡Æ™‡Æ§‡Øà ‡Æâ‡Æ±‡ØÅ‡Æ§‡Æø‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æµ‡ØÅ‡ÆÆ‡Øç: ollama serve",
            "kannada": f"LLM ‡≤∏‡≥á‡≤µ‡≥Ü‡≤ó‡≥Ü ‡≤∏‡≤Ç‡≤™‡≤∞‡≥ç‡≤ï‡≤ø‡≤∏‡≤≤‡≥Å ‡≤∏‡≤æ‡≤ß‡≥ç‡≤Ø‡≤µ‡≤æ‡≤ó‡≤≤‡≤ø‡≤≤‡≥ç‡≤≤. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å Ollama ‡≤ö‡≤æ‡≤≤‡≤®‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø‡≤¶‡≥Ü ‡≤é‡≤Ç‡≤¶‡≥Å ‡≤ñ‡≤ö‡≤ø‡≤§‡≤™‡≤°‡≤ø‡≤∏‡≤ø: ollama serve",
            "malayalam": f"LLM ‡¥∏‡µá‡¥µ‡¥®‡¥µ‡µÅ‡¥Æ‡¥æ‡¥Ø‡¥ø ‡¥¨‡¥®‡µç‡¥ß‡¥™‡µç‡¥™‡µÜ‡¥ü‡¥æ‡µª ‡¥ï‡¥¥‡¥ø‡¥û‡µç‡¥û‡¥ø‡¥≤‡µç‡¥≤. ‡¥¶‡¥Ø‡¥µ‡¥æ‡¥Ø‡¥ø Ollama ‡¥™‡µç‡¥∞‡¥µ‡µº‡¥§‡µç‡¥§‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ‡¥µ‡µÜ‡¥®‡µç‡¥®‡µç ‡¥â‡¥±‡¥™‡µç‡¥™‡¥æ‡¥ï‡µç‡¥ï‡µÅ‡¥ï: ollama serve",
            "gujarati": f"LLM ‡™∏‡´á‡™µ‡™æ ‡™∏‡™æ‡™•‡´á ‡™ï‡™®‡´á‡™ï‡´ç‡™ü ‡™•‡™à ‡™∂‡™ï‡´ç‡™Ø‡´Å‡™Ç ‡™®‡™•‡´Ä. ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™ñ‡™æ‡™§‡™∞‡´Ä ‡™ï‡™∞‡´ã ‡™ï‡´á Ollama ‡™ö‡™æ‡™≤‡´Ä ‡™∞‡™π‡´ç‡™Ø‡´Å‡™Ç ‡™õ‡´á: ollama serve",
        }
        return error_messages.get(language.lower(), error_messages["english"])
    except requests.exceptions.Timeout:
        logger.error("Request timeout to Ollama")
        timeout_messages = {
            "english": "The LLM service took too long to respond. Please try again.",
            "hindi": "LLM ‡§∏‡•á‡§µ‡§æ ‡§®‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§¶‡•á‡§®‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§Æ‡§Ø ‡§≤‡§ø‡§Ø‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§",
            "telugu": "LLM ‡∞∏‡±á‡∞µ‡∞ï‡±Å ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞∏‡±ç‡∞™‡∞Ç‡∞¶‡∞® ‡∞á‡∞µ‡±ç‡∞µ‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞∏‡∞Æ‡∞Ø‡∞Ç ‡∞™‡∞ü‡±ç‡∞ü‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø‡•§",
            "marathi": "LLM ‡§∏‡•á‡§µ‡•á‡§®‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§∏‡§æ‡§¶ ‡§¶‡•á‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§ñ‡•Ç‡§™ ‡§µ‡•á‡§≥ ‡§ò‡•á‡§§‡§≤‡§æ. ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡§∞‡§æ.",
            "bengali": "LLM ‡¶™‡¶∞‡¶ø‡¶∑‡ßá‡¶¨‡¶æ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶ú‡¶æ‡¶®‡¶æ‡¶§‡ßá ‡¶Ö‡¶®‡ßá‡¶ï ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶®‡¶ø‡¶Ø‡¶º‡ßá‡¶õ‡ßá‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§",
            "tamil": "LLM ‡Æö‡Øá‡Æµ‡Øà ‡Æ™‡Æ§‡Æø‡Æ≤‡Æ≥‡Æø‡Æï‡Øç‡Æï ‡ÆÖ‡Æ§‡Æø‡Æï ‡Æ®‡Øá‡Æ∞‡ÆÆ‡Øç ‡Æé‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡Æ§‡ØÅ. ‡Æ§‡ÆØ‡Æµ‡ØÅ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ ‡ÆÆ‡ØÄ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡ÆÆ‡ØÅ‡ÆØ‡Æ±‡Øç‡Æö‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç‡•§",
            "kannada": "LLM ‡≤∏‡≥á‡≤µ‡≥Ü‡≤Ø‡≥Å ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≤ø‡≤∏‡≤≤‡≥Å ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤∏‡≤Æ‡≤Ø ‡≤§‡≥Ü‡≤ó‡≥Ü‡≤¶‡≥Å‡≤ï‡≥ä‡≤Ç‡≤°‡≤ø‡≤¶‡≥Ü. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≤ø.",
            "malayalam": "LLM ‡¥∏‡µá‡¥µ‡¥®‡¥Ç ‡¥™‡µç‡¥∞‡¥§‡¥ø‡¥ï‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥µ‡¥≥‡¥∞‡µÜ‡¥Ø‡¥ß‡¥ø‡¥ï‡¥Ç ‡¥∏‡¥Æ‡¥Ø‡¥Æ‡µÜ‡¥ü‡µÅ‡¥§‡µç‡¥§‡µÅ. ‡¥¶‡¥Ø‡¥µ‡¥æ‡¥Ø‡¥ø ‡¥µ‡µÄ‡¥£‡µç‡¥ü‡µÅ‡¥Ç ‡¥∂‡µç‡¥∞‡¥Æ‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï.",
            "gujarati": "LLM ‡™∏‡´á‡™µ‡™æ‡™è ‡™™‡´ç‡™∞‡™§‡™ø‡™≠‡™æ‡™µ ‡™Ü‡™™‡™µ‡™æ‡™Æ‡™æ‡™Ç ‡™ñ‡´Ç‡™¨ ‡™∏‡™Æ‡™Ø ‡™≤‡´Ä‡™ß‡´ã. ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™´‡™∞‡´Ä‡™•‡´Ä ‡™™‡´ç‡™∞‡™Ø‡™æ‡™∏ ‡™ï‡™∞‡´ã.",
        }
        return timeout_messages.get(language.lower(), timeout_messages["english"])
    except Exception as e:
        logger.exception("Error in answer_medical_question: %s", e)
        logger.error("Full error details: %s", str(e))
        error_messages = {
            "english": f"Error processing your question: {str(e)[:100]}. Please try again or consult a healthcare professional.",
            "hindi": f"‡§Ü‡§™‡§ï‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡•ã ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {str(e)[:100]}‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡§É ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç ‡§Ø‡§æ ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§™‡•á‡§∂‡•á‡§µ‡§∞ ‡§∏‡•á ‡§™‡§∞‡§æ‡§Æ‡§∞‡•ç‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§",
            "telugu": f"‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç ‡∞ö‡±á‡∞Ø‡∞°‡∞Ç‡∞≤‡±ã ‡∞≤‡±ã‡∞™‡∞Ç: {str(e)[:100]}‡•§ ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø ‡∞≤‡±á‡∞¶‡∞æ ‡∞Ü‡∞∞‡±ã‡∞ó‡±ç‡∞Ø ‡∞∏‡∞Ç‡∞∞‡∞ï‡±ç‡∞∑‡∞£ ‡∞®‡∞ø‡∞™‡±Å‡∞£‡±Å‡∞°‡∞ø‡∞®‡∞ø ‡∞∏‡∞Ç‡∞™‡±ç‡∞∞‡∞¶‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø‡•§",
            "marathi": f"‡§§‡•Å‡§Æ‡§ö‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•ç‡§∞‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§ï‡§∞‡§§‡§æ‡§®‡§æ ‡§§‡•ç‡§∞‡•Å‡§ü‡•Ä: {str(e)[:100]}‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡§∞‡§æ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§Ü‡§∞‡•ã‡§ó‡•ç‡§Ø ‡§∏‡•á‡§µ‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§∏‡§æ‡§Ø‡§ø‡§ï‡§æ‡§Ç‡§∂‡•Ä ‡§∏‡§≤‡•ç‡§≤‡§æ‡§Æ‡§∏‡§≤‡§§ ‡§ï‡§∞‡§æ.",
            "bengali": f"‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶™‡ßç‡¶∞‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶æ ‡¶ï‡¶∞‡¶§‡ßá ‡¶§‡ßç‡¶∞‡ßÅ‡¶ü‡¶ø: {str(e)[:100]}‡•§ ‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá ‡¶Ü‡¶¨‡¶æ‡¶∞ ‡¶ö‡ßá‡¶∑‡ßç‡¶ü‡¶æ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶¨‡¶æ ‡¶∏‡ßç‡¶¨‡¶æ‡¶∏‡ßç‡¶•‡ßç‡¶Ø‡¶∏‡ßá‡¶¨‡¶æ ‡¶™‡ßá‡¶∂‡¶æ‡¶¶‡¶æ‡¶∞‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶™‡¶∞‡¶æ‡¶Æ‡¶∞‡ßç‡¶∂ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§",
            "tamil": f"‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø‡ÆØ‡Øà ‡Æö‡ØÜ‡ÆØ‡Æ≤‡Ææ‡Æï‡Øç‡Æï‡ØÅ‡Æµ‡Æ§‡Æø‡Æ≤‡Øç ‡Æ™‡Æø‡Æ¥‡Øà: {str(e)[:100]}‡•§ ‡Æ§‡ÆØ‡Æµ‡ØÅ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ ‡ÆÆ‡ØÄ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡ÆÆ‡ØÅ‡ÆØ‡Æ±‡Øç‡Æö‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ≤‡Øç‡Æ≤‡Æ§‡ØÅ ‡Æö‡ØÅ‡Æï‡Ææ‡Æ§‡Ææ‡Æ∞ ‡Æ®‡Æø‡Æ™‡ØÅ‡Æ£‡Æ∞‡Øà ‡ÆÖ‡Æ£‡ØÅ‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç‡•§",
            "kannada": f"‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≥Å‡≤µ‡≤≤‡≥ç‡≤≤‡≤ø ‡≤¶‡≥ã‡≤∑: {str(e)[:100]}‡•§ ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≤ø ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤Ü‡≤∞‡≥ã‡≤ó‡≥ç‡≤Ø ‡≤∏‡≥á‡≤µ‡≤æ ‡≤µ‡≥É‡≤§‡≥ç‡≤§‡≤ø‡≤™‡≤∞‡≤∞‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≤Ç‡≤™‡≤∞‡≥ç‡≤ï‡≤ø‡≤∏‡≤ø‡•§",
            "malayalam": f"‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥ö‡µã‡¥¶‡µç‡¥Ø‡¥Ç ‡¥™‡µç‡¥∞‡µã‡¥∏‡¥∏‡µç‡¥∏‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥Ø‡µÅ‡¥®‡µç‡¥®‡¥§‡¥ø‡µΩ ‡¥™‡¥ø‡¥∂‡¥ï‡µç: {str(e)[:100]}‡•§ ‡¥¶‡¥Ø‡¥µ‡¥æ‡¥Ø‡¥ø ‡¥µ‡µÄ‡¥£‡µç‡¥ü‡µÅ‡¥Ç ‡¥∂‡µç‡¥∞‡¥Æ‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï ‡¥Ö‡¥≤‡µç‡¥≤‡µÜ‡¥ô‡µç‡¥ï‡¥ø‡µΩ ‡¥Ü‡¥∞‡µã‡¥ó‡µç‡¥Ø ‡¥∏‡µá‡¥µ‡¥æ ‡¥™‡µç‡¥∞‡µä‡¥´‡¥∑‡¥£‡¥≤‡µÅ‡¥Æ‡¥æ‡¥Ø‡¥ø ‡¥ï‡µà‡¥ï‡µã‡µº‡¥§‡µç‡¥§‡µç ‡¥™‡¥∞‡¥ø‡¥∂‡µã‡¥ß‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï‡•§",
            "gujarati": f"‡™§‡™Æ‡™æ‡™∞‡™æ ‡™™‡´ç‡™∞‡™∂‡´ç‡™®‡™®‡´á ‡™™‡´ç‡™∞‡™ï‡´ç‡™∞‡™ø‡™Ø‡™æ ‡™ï‡™∞‡™µ‡™æ‡™Æ‡™æ‡™Ç ‡™≠‡´Ç‡™≤: {str(e)[:100]}‡•§ ‡™ï‡´É‡™™‡™æ ‡™ï‡™∞‡´Ä‡™®‡´á ‡™´‡™∞‡´Ä‡™•‡´Ä ‡™™‡´ç‡™∞‡™Ø‡™æ‡™∏ ‡™ï‡™∞‡´ã ‡™Ö‡™•‡™µ‡™æ ‡™Ü‡™∞‡´ã‡™ó‡´ç‡™Ø ‡™∏‡´á‡™µ‡™æ ‡™µ‡´ç‡™Ø‡™µ‡™∏‡™æ‡™Ø‡™ø‡™ï‡™®‡´Ä ‡™∏‡™≤‡™æ‡™π ‡™≤‡´ã.",
        }
        return error_messages.get(language.lower(), error_messages["english"])